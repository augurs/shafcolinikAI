{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d8845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BODY MEASUREMENTS ===\n",
      "Chest Circumference: 103.6 cm\n",
      "Waist Circumference: 72.2 cm\n",
      "Hip Circumference: 56.0 cm\n",
      "\n",
      "=== DEBUG INFO ===\n",
      "Detected pose height: 1.357 m\n",
      "Scale factor: 1.253\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "from typing import Dict, Tuple\n",
    "import math\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "\n",
    "def euclidean_distance_3d(p1, p2) -> float:\n",
    "    \"\"\"Calculate 3D Euclidean distance in meters.\"\"\"\n",
    "    return np.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2 + (p1.z - p2.z)**2)\n",
    "\n",
    "\n",
    "def euclidean_distance_2d(p1, p2) -> float:\n",
    "    \"\"\"Calculate 2D Euclidean distance.\"\"\"\n",
    "    return np.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)\n",
    "\n",
    "\n",
    "class Landmark3D:\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "\n",
    "def estimate_body_measurements(pil_image: Image.Image, user_height_cm: float = 170) -> Dict:\n",
    "    \"\"\"\n",
    "    Estimates body measurements (waist, chest, hip) from a single image using pose estimation.\n",
    "    \n",
    "    Args:\n",
    "        pil_image: PIL Image of a person standing upright\n",
    "        user_height_cm: User's actual height in centimeters for scaling\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing measurements and annotated image\n",
    "    \"\"\"\n",
    "    image_rgb = np.array(pil_image.convert(\"RGB\"))\n",
    "    output_image = image_rgb.copy()\n",
    "    height, width, _ = output_image.shape\n",
    "    \n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        if not results.pose_landmarks or not results.pose_world_landmarks:\n",
    "            raise ValueError(\"No pose detected. Please ensure the person is clearly visible and standing upright.\")\n",
    "        \n",
    "        # Draw pose landmarks\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=output_image,\n",
    "            landmark_list=results.pose_landmarks,\n",
    "            connections=mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=3),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 128, 255), thickness=2)\n",
    "        )\n",
    "        \n",
    "        # Get landmark accessor functions\n",
    "        world_landmarks = results.pose_world_landmarks.landmark\n",
    "        pixel_landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "        def get_world(name): \n",
    "            return world_landmarks[mp_pose.PoseLandmark[name].value]\n",
    "        \n",
    "        def get_pixel(name): \n",
    "            return pixel_landmarks[mp_pose.PoseLandmark[name].value]\n",
    "        \n",
    "        # Calculate body height from pose for scaling\n",
    "        head_top = get_world(\"NOSE\")  # Approximate head top\n",
    "        left_ankle = get_world(\"LEFT_ANKLE\")\n",
    "        right_ankle = get_world(\"RIGHT_ANKLE\")\n",
    "        \n",
    "        # Use average of both ankles for ground reference\n",
    "        ground_y = (left_ankle.y + right_ankle.y) / 2\n",
    "        pose_height_m = abs(head_top.y - ground_y)\n",
    "        \n",
    "        # Scaling factor to convert pose measurements to real-world measurements\n",
    "        scale_factor = user_height_cm / (pose_height_m * 100)  # Convert to cm scale\n",
    "        \n",
    "        # === CHEST MEASUREMENT ===\n",
    "        left_shoulder = get_world(\"LEFT_SHOULDER\")\n",
    "        right_shoulder = get_world(\"RIGHT_SHOULDER\")\n",
    "        \n",
    "        # Get elbow landmarks to better estimate chest/bust area\n",
    "        try:\n",
    "            left_elbow = get_world(\"LEFT_ELBOW\")\n",
    "            right_elbow = get_world(\"RIGHT_ELBOW\")\n",
    "            # Use elbow x-coordinates for chest width (arms naturally at chest level)\n",
    "            chest_width_m = abs(left_elbow.x - right_elbow.x)\n",
    "        except:\n",
    "            # Fallback to shoulder-based measurement\n",
    "            chest_width_m = euclidean_distance_3d(left_shoulder, right_shoulder)\n",
    "        \n",
    "        # More conservative chest circumference calculation\n",
    "        # Chest is typically 1.8-2.2 times the width measurement\n",
    "        chest_circumference_cm = chest_width_m * 100 * scale_factor * 2.0\n",
    "        \n",
    "        # === WAIST MEASUREMENT ===\n",
    "        left_hip = get_world(\"LEFT_HIP\")\n",
    "        right_hip = get_world(\"RIGHT_HIP\")\n",
    "        \n",
    "        # Waist is typically at the narrowest point between chest and hips\n",
    "        waist_left = Landmark3D(\n",
    "            x=(left_shoulder.x + left_hip.x) / 2 * 0.9,  # Narrower than shoulders/hips\n",
    "            y=(left_shoulder.y + left_hip.y) / 2,\n",
    "            z=(left_shoulder.z + left_hip.z) / 2\n",
    "        )\n",
    "        waist_right = Landmark3D(\n",
    "            x=(right_shoulder.x + right_hip.x) / 2 * 0.9,\n",
    "            y=(right_shoulder.y + right_hip.y) / 2,\n",
    "            z=(right_shoulder.z + right_hip.z) / 2\n",
    "        )\n",
    "        \n",
    "        # More accurate waist calculation using hip and shoulder reference\n",
    "        waist_width_m = euclidean_distance_3d(waist_left, waist_right)\n",
    "        waist_circumference_cm = waist_width_m * 100 * scale_factor * 2.5  # More realistic multiplier\n",
    "        \n",
    "        # === HIP MEASUREMENT ===\n",
    "        hip_width_m = euclidean_distance_3d(left_hip, right_hip)\n",
    "        hip_circumference_cm = hip_width_m * 100 * scale_factor * 2.2  # More realistic multiplier\n",
    "        \n",
    "        # Draw measurement points\n",
    "        def project_to_pixel(world_lm):\n",
    "            \"\"\"Convert world landmark to pixel coordinates\"\"\"\n",
    "            return int(world_lm.x * width + width/2), int(-world_lm.y * height + height/2)\n",
    "        \n",
    "        # Mark key measurement points including elbows for chest reference\n",
    "        measurement_points = [\n",
    "            (\"LEFT_SHOULDER\", left_shoulder, (255, 0, 0)),\n",
    "            (\"RIGHT_SHOULDER\", right_shoulder, (255, 0, 0)),\n",
    "            (\"LEFT_HIP\", left_hip, (0, 255, 0)),\n",
    "            (\"RIGHT_HIP\", right_hip, (0, 255, 0)),\n",
    "        ]\n",
    "        \n",
    "        # Add elbow points if available for chest measurement verification\n",
    "        try:\n",
    "            left_elbow = get_world(\"LEFT_ELBOW\")\n",
    "            right_elbow = get_world(\"RIGHT_ELBOW\")\n",
    "            measurement_points.extend([\n",
    "                (\"LEFT_ELBOW\", left_elbow, (255, 255, 0)),\n",
    "                (\"RIGHT_ELBOW\", right_elbow, (255, 255, 0))\n",
    "            ])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for name, landmark, color in measurement_points:\n",
    "            x, y = project_to_pixel(landmark)\n",
    "            # Clamp coordinates to image bounds\n",
    "            x = max(0, min(width-1, x))\n",
    "            y = max(0, min(height-1, y))\n",
    "            cv2.circle(output_image, (x, y), 8, color, -1)\n",
    "            cv2.putText(output_image, name.replace(\"_\", \" \"), (x + 10, y - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Add measurement text to image\n",
    "        measurements_text = [\n",
    "            f\"Chest: {chest_circumference_cm:.1f} cm\",\n",
    "            f\"Waist: {waist_circumference_cm:.1f} cm\",\n",
    "            f\"Hip: {hip_circumference_cm:.1f} cm\",\n",
    "            f\"Height: {user_height_cm} cm (input)\"\n",
    "        ]\n",
    "        \n",
    "        for i, text in enumerate(measurements_text):\n",
    "            cv2.putText(output_image, text, (20, 40 + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "            cv2.putText(output_image, text, (20, 40 + i * 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 1)\n",
    "        \n",
    "        return {\n",
    "            \"annotated_image\": Image.fromarray(output_image),\n",
    "            \"measurements_cm\": {\n",
    "                \"chest_circumference_cm\": round(chest_circumference_cm, 1),\n",
    "                \"waist_circumference_cm\": round(waist_circumference_cm, 1),\n",
    "                \"hip_circumference_cm\": round(hip_circumference_cm, 1)\n",
    "            },\n",
    "            \"debug_info\": {\n",
    "                \"pose_height_m\": round(pose_height_m, 3),\n",
    "                \"scale_factor\": round(scale_factor, 3),\n",
    "                \"chest_width_m\": round(chest_width_m, 4),\n",
    "                \"waist_width_m\": round(waist_width_m, 4),\n",
    "                \"hip_width_m\": round(hip_width_m, 4)\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    # Constants\n",
    "    user_height_cm = 170  # Replace with actual user height\n",
    "    image_path = \"../images/front-image.png\"  # Replace with your image path\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Get measurements\n",
    "        result = estimate_body_measurements(img, user_height_cm)\n",
    "        \n",
    "        # Display results\n",
    "        result[\"annotated_image\"].show()\n",
    "        \n",
    "        measurements = result[\"measurements_cm\"]\n",
    "        print(\"\\n=== BODY MEASUREMENTS ===\")\n",
    "        print(f\"Chest Circumference: {measurements['chest_circumference_cm']} cm\")\n",
    "        print(f\"Waist Circumference: {measurements['waist_circumference_cm']} cm\")\n",
    "        print(f\"Hip Circumference: {measurements['hip_circumference_cm']} cm\")\n",
    "        \n",
    "        print(\"\\n=== DEBUG INFO ===\")\n",
    "        debug = result[\"debug_info\"]\n",
    "        print(f\"Detected pose height: {debug['pose_height_m']} m\")\n",
    "        print(f\"Scale factor: {debug['scale_factor']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure:\")\n",
    "        print(\"1. The image path is correct\")\n",
    "        print(\"2. The person is clearly visible and standing upright\")\n",
    "        print(\"3. The person is facing the camera\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
